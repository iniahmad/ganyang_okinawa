{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def float_to_custom_binary(float_value):\n",
    "    # Determine the sign bit\n",
    "    sign_bit = 0 if float_value >= 0 else 1\n",
    "\n",
    "    # Get the absolute value of the float for further processing\n",
    "    abs_value = abs(float_value)\n",
    "\n",
    "    # Separate the integer and fractional parts\n",
    "    integer_part = int(abs_value)\n",
    "    fractional_part = abs_value - integer_part\n",
    "\n",
    "    # Convert the integer part to binary (4 bits)\n",
    "    integer_binary = format(integer_part & 0b1111, '04b')\n",
    "\n",
    "    # Convert the fractional part to binary (27 bits)\n",
    "    fractional_binary = ''\n",
    "    for _ in range(11):\n",
    "        fractional_part *= 2\n",
    "        bit = int(fractional_part)\n",
    "        fractional_binary += str(bit)\n",
    "        fractional_part -= bit\n",
    "\n",
    "    # Combine all parts into a single binary string\n",
    "    custom_binary = f\"{sign_bit}{integer_binary}{fractional_binary}\"\n",
    "\n",
    "    return custom_binary\n",
    "\n",
    "def binary_to_float(binary_str):\n",
    "    \"\"\"Convert a 32-bit binary string to a float.\"\"\"\n",
    "    sign = int(binary_str[0])\n",
    "    integer_part = int(binary_str[1:5], 2)\n",
    "    fractional_part = binary_str[5:]\n",
    "    frac_value = 0.0\n",
    "    for i, bit in enumerate(fractional_part):\n",
    "        if bit == '1':\n",
    "            frac_value += 1 / (2 ** (i + 1))\n",
    "    float_value = integer_part + frac_value\n",
    "    if sign == 1:\n",
    "        float_value = -float_value\n",
    "    return float_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "// Testcase 22 False\n",
      "x = {\n",
      "16'b0000001101010011,\n",
      "16'b0000001101001001,\n",
      "16'b0000010001101110,\n",
      "16'b0000001110101001,\n",
      "16'b0000001110010101,\n",
      "16'b0000010000010001,\n",
      "16'b0000010011000001,\n",
      "16'b0000010100010000,\n",
      "16'b0000001110001110,\n",
      "16'b0000001110010101\n",
      "};\n",
      "\n",
      "#600;\n",
      "reset = 1;\n",
      "x = 0;\n",
      "// Wait for global reset to finish\n",
      "#10;\n",
      "reset = 0;\n",
      "\n",
      "// Testcase 21 False\n",
      "x = {\n",
      "16'b0000010110000000,\n",
      "16'b0000010101111001,\n",
      "16'b0000011001101100,\n",
      "16'b0000011011010001,\n",
      "16'b0000011010011100,\n",
      "16'b0000011100100111,\n",
      "16'b0000011011010001,\n",
      "16'b0000010111001111,\n",
      "16'b0000011001011101,\n",
      "16'b0000011001011001\n",
      "};\n",
      "\n",
      "#600;\n",
      "reset = 1;\n",
      "x = 0;\n",
      "// Wait for global reset to finish\n",
      "#10;\n",
      "reset = 0;\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Testbench data\n",
    "import numpy as np\n",
    "\n",
    "# Define the values as a 2D NumPy array\n",
    "values = np.array([\n",
    "    [0.52158273, 0.24820144, 0.79676259, 0.55035971, 0.52697842, 0.16366906, 0.16546763, 0.73920863, 0.46402878, 0.34352518],\n",
    "    [0.55555556, 0.46296296, 0.41077441, 0.42760943, 0.33501684, 0.57575758, 0.33164983, 0.52356902, 0.44949495, 0.42760943],\n",
    "    [0.73218673, 0.75675676, 0.74692875, 0.72727273, 0.71007371, 0.70761671, 0.69041769, 0.71498771, 0.72481572, 0.75429975],\n",
    "    [0.41613924, 0.35601266, 0.36392405, 0.3971519,  0.3528481,  0.36234177, 0.38132911, 0.27531646, 0.54588608, 0.40981013],\n",
    "    [0.46638655, 0.79621849, 0.36344538, 0.71848739, 0.41806723, 0.3802521,  0.3802521,  0.59033613, 0.57352941, 0.60504202],\n",
    "    [0.7002457,  0.66093366, 0.66830467, 0.74447174, 0.75184275, 0.68550369, 0.6953317,  0.7002457,  0.71007371, 0.65847666],\n",
    "    [0.54871795, 0.34358974, 1.0,        0.74102564, 0.72564103, 0.46923077, 0.94871795, 0.74102564, 0.73333333, 0.46410256],\n",
    "    [0.54411765, 0.48109244, 0.39705882, 0.57563025, 0.22268908, 0.22478992, 0.91176471, 0.41806723, 0.71428571, 0.44327731],\n",
    "    [0.78343949, 0.78343949, 0.69002123, 0.68577495, 0.74309979, 0.75159236, 0.73460722, 0.66878981, 0.74734607, 0.78768577],\n",
    "    [0.75776398, 0.73913043, 0.72049689, 0.77329193, 0.76397516, 0.7484472,  0.72981366, 0.7484472,  0.73602484, 0.75776398],\n",
    "    [0.18642351, 0.26342452, 0.23100304, 0.22087133, 0.20364742, 0.32826748, 0.20263425, 0.26342452, 0.22695035, 0.19756839],\n",
    "    [0.37025316, 0.38449367, 0.13765823, 0.13765823, 0.53639241, 0.42088608, 0.16297468, 0.10126582, 0.44303797, 0.47310127],\n",
    "    [0.74927954, 0.74639769, 0.74063401, 0.74351585, 0.77233429, 0.74063401, 0.75216138, 0.73198847, 0.72910663, 0.74063401],\n",
    "    [0.61663286, 0.62677485, 0.61866126, 0.62677485, 0.62271805, 0.62474645, 0.64908722, 0.55578093, 0.67951318, 0.65517241],\n",
    "    [0.37668919, 0.6875,     0.36824324, 0.63851351, 0.47635135, 0.43918919, 0.47972973, 0.58952703, 0.54898649, 0.55574324],\n",
    "    [0.7173913,  0.70496894, 0.71118012, 0.69254658, 0.72049689, 0.72360248, 0.71118012, 0.69254658, 0.70496894, 0.70807453],\n",
    "    [0.77616279, 0.61337209, 0.59302326, 0.60174419, 0.59011628, 0.59593023, 0.38953488, 0.7994186,  0.55232558, 0.64534884],\n",
    "    [0.72542373, 0.73898305, 0.71355932, 0.6779661,  0.68305085, 0.71864407, 0.73389831, 0.7,        0.67118644, 0.68135593],\n",
    "    [0.34810127, 0.40031646, 0.37341772, 0.35601266, 0.36867089, 0.46044304, 0.42088608, 0.52689873, 0.34018987, 0.3528481 ],\n",
    "    [0.6953317,  0.6977887,  0.72727273, 0.73710074, 0.74692875, 0.71253071, 0.69041769, 0.68796069, 0.6953317,  0.71498771],\n",
    "    [0.61038961, 0.59253247, 0.61688312, 0.61850649, 0.58441558, 0.61525974, 0.60227273, 0.90097403, 0.46266234, 0.67857143],\n",
    "    [0.6879562,  0.68430657, 0.80291971, 0.85218978, 0.82664234, 0.89416058, 0.85218978, 0.72627737, 0.79562044, 0.79379562],\n",
    "    [0.41582492, 0.41077441, 0.55387205, 0.45791246, 0.44781145, 0.50841751, 0.59427609, 0.63299663, 0.44444444, 0.44781145],\n",
    "    [0.7483871,  0.73870968, 0.67419355, 0.79677419, 0.71612903, 0.77096774, 0.8,        0.79032258, 0.75806452, 0.7483871 ],\n",
    "    [0.76080692, 0.75504323, 0.75504323, 0.77809798, 0.76945245, 0.76080692, 0.76657061, 0.78962536, 0.78386167, 0.74639769],\n",
    "    [0.57627119, 0.55932203, 0.51412429, 0.51694915, 0.52259887, 0.50847458, 0.52542373, 0.52542373, 0.56497175, 0.46045198],\n",
    "    [0.55367232, 0.56214689, 0.57062147, 0.58474576, 0.57062147, 0.55367232, 0.53107345, 0.51977401, 0.52259887, 0.53954802],\n",
    "    [0.33227848, 0.47151899, 0.38449367, 0.48575949, 0.33702532, 0.33227848, 0.31487342, 0.33544304, 0.39240506, 0.4335443 ],\n",
    "    [0.63081395, 0.60465116, 0.61046512, 0.5872093,  0.61046512, 0.55232558, 0.6627907,  0.62209302, 0.41569767, 0.7994186 ],\n",
    "    [0.73602484, 0.7515528,  0.76397516, 0.73913043, 0.72981366, 0.74534161, 0.76708075, 0.73913043, 0.71118012, 0.72049689]\n",
    "])\n",
    "\n",
    "boolean_values = np.array([\n",
    "    True, False, False, True, True, False, True, True, False, False,\n",
    "    True, True, False, False, True, False, True, False, False, False,\n",
    "    False, False, False, False, False, False, False, False, True, False\n",
    "])\n",
    "\n",
    "# True label (urut atas ke bawah)\n",
    "'''\n",
    "0True\n",
    "1False\n",
    "2False\n",
    "3True\n",
    "4True\n",
    "5False\n",
    "6True\n",
    "7True\n",
    "8False\n",
    "False\n",
    "True\n",
    "True\n",
    "False\n",
    "False\n",
    "True\n",
    "False\n",
    "True\n",
    "False\n",
    "False\n",
    "False\n",
    "False\n",
    "False\n",
    "False\n",
    "False\n",
    "False\n",
    "False\n",
    "False\n",
    "False\n",
    "True\n",
    "False\n",
    "'''\n",
    "index_up = 22\n",
    "print(f\"// Testcase {index_up} {boolean_values[index_up]}\")\n",
    "print(\"x = {\")\n",
    "val0 = values[index_up]\n",
    "for i in range(len(val0)):\n",
    "    if i != len(val0)-1:\n",
    "        print(f\"16'b{float_to_custom_binary(val0[i])},\")\n",
    "    else:\n",
    "        print(f\"16'b{float_to_custom_binary(val0[i])}\")\n",
    "print(\"};\")\n",
    "print('''\n",
    "#600;\n",
    "reset = 1;\n",
    "x = 0;\n",
    "// Wait for global reset to finish\n",
    "#10;\n",
    "reset = 0;\n",
    "''')\n",
    "\n",
    "index_down = 23\n",
    "print(f\"// Testcase {index_down} {boolean_values[index_up]}\")\n",
    "print(\"x = {\")\n",
    "val1 = values[index_down]\n",
    "for i in range(len(val1)):\n",
    "    if i != len(val1)-1:\n",
    "        print(f\"16'b{float_to_custom_binary(val1[i])},\")\n",
    "    else:\n",
    "        print(f\"16'b{float_to_custom_binary(val1[i])}\")\n",
    "print(\"};\")\n",
    "print('''\n",
    "#600;\n",
    "reset = 1;\n",
    "x = 0;\n",
    "// Wait for global reset to finish\n",
    "#10;\n",
    "reset = 0;\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w_enc_1 = {\n",
      "16'b0000010000010001,\n",
      "16'b0000010111100111,\n",
      "16'b0000010010101000,\n",
      "16'b1000000100000110,\n",
      "16'b0000001000100000,\n",
      "16'b0000001101001001,\n",
      "16'b1000000101100100,\n",
      "16'b0000001001101110,\n",
      "16'b1000101011010000,\n",
      "16'b1000001101110010,\n",
      "16'b1000001110110000,\n",
      "16'b0000100010001101,\n",
      "16'b0000001010101100,\n",
      "16'b0000010110010011,\n",
      "16'b0001000101001000,\n",
      "16'b0000001101001101,\n",
      "16'b0000001000101110,\n",
      "16'b1000110000000000,\n",
      "16'b1000001000010000,\n",
      "16'b0000001101011000,\n",
      "16'b1001001111110110,\n",
      "16'b1000100110000011,\n",
      "16'b1000010010001011,\n",
      "16'b0001001011011111,\n",
      "16'b0000001000101101,\n",
      "16'b0000010011110011,\n",
      "16'b0001000011010011,\n",
      "16'b0000001110011101,\n",
      "16'b0000010000110110,\n",
      "16'b1000101001101111,\n",
      "16'b1000001011010011,\n",
      "16'b1000001000111100,\n",
      "16'b1000101101100011,\n",
      "16'b1000000000011111,\n",
      "16'b1000000111110101,\n",
      "16'b0000010100101110,\n",
      "16'b1000000000100001,\n",
      "16'b0000011101110011,\n",
      "16'b0000110100010100,\n",
      "16'b1000001000011001,\n",
      "16'b0000000100000011,\n",
      "16'b1000011011110111,\n",
      "16'b1000001101110111,\n",
      "16'b1000001010101111,\n",
      "16'b1001001010101011,\n",
      "16'b0001001010111010,\n",
      "16'b1000001010000110,\n",
      "16'b1000000100011110,\n",
      "16'b0000001011111110,\n",
      "16'b0000011001110000,\n",
      "16'b0001010101100000,\n",
      "16'b1001000001101011,\n",
      "16'b0000001110011100,\n",
      "16'b1000000110011100,\n",
      "16'b0000000101100000,\n",
      "16'b0000010110101001,\n",
      "16'b1000100000101101,\n",
      "16'b0000101000110010,\n",
      "16'b0000000110111111,\n",
      "16'b0000010100111010,\n",
      "};\n",
      "b_enc_1 = {\n",
      "16'b0000001111101011,\n",
      "16'b0000010110111011,\n",
      "16'b1000010111111101,\n",
      "16'b1000001100001000,\n",
      "16'b0000000110100100,\n",
      "16'b1000000000111110,\n",
      "};\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Matriks weights dan biases baru\n",
    "weights = np.array([\n",
    "    [ 0.6534264,   0.21859674,  1.2745217,  -1.0222182,   0.7077743,   0.17227717],\n",
    "    [-0.20127988,  0.4514176,  -2.0522668,   2.672189,    0.80515337,  0.37432212],\n",
    "    [-0.13975152, -0.31581482,  2.3408759,  -2.3335826,  -0.33572876, -0.43321046],\n",
    "    [-0.8709897,   0.12654892, -0.26234385,  1.635064,    0.9312294,  -0.01634913],\n",
    "    [ 0.647927,   -0.24472286, -0.01513885, -1.4235544,  -0.27940372, -0.35318562],\n",
    "    [-1.3046579,   0.52666247,  0.45172158,  2.103228,    0.6189593,   0.27229634],\n",
    "    [ 2.3592968,  -0.5682007,  -1.1892892,  -2.4954329,   0.41806337, -0.25829604],\n",
    "    [-1.5002532,   0.27253047,  0.41295567,  2.1604352,   0.69707775,  0.33440912],\n",
    "    [ 1.0692248,  -0.46117586, -0.43102968, -1.3517272,   0.30404046, -0.17390116],\n",
    "    [ 0.41081432,  0.26590595, -0.12813525,  0.58229923,  0.7379277,   0.50835204]\n",
    "])\n",
    "\n",
    "biases = np.array([-0.03052479,  0.20527796, -0.3793689, -0.7488852,  0.7164985,  0.49002257])\n",
    "\n",
    "# Flattening the arrays in reverse order\n",
    "flattened_weights = weights.flatten()[::-1]\n",
    "flattened_biases = biases.flatten()[::-1]\n",
    "\n",
    "# print(\"Flattened Weights (Reversed):\", len(flattened_weights))\n",
    "# print(\"Flattened Biases (Reversed):\", flattened_biases)\n",
    "print(\"w_enc_1 = {\")\n",
    "for i in range(len(flattened_weights)):\n",
    "    print(f\"16'b{float_to_custom_binary(flattened_weights[i])},\")\n",
    "print(\"};\")    \n",
    "\n",
    "print(\"b_enc_1 = {\")\n",
    "for i in range(len(flattened_biases)):\n",
    "    print(f\"16'b{float_to_custom_binary(flattened_biases[i])},\")\n",
    "print(\"};\")    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w_enc_2_mean = {\n",
      "16'b0000011110111111,\n",
      "16'b0000001100011010,\n",
      "16'b1001000011001011,\n",
      "16'b1000101000000101,\n",
      "16'b0000011010000001,\n",
      "16'b1000110010101100\n",
      "};\n",
      "b_enc_2_mean = {\n",
      "16'b0000001000011110\n",
      "};\n",
      "w_enc_2_var = {\n",
      "16'b1001001001011000,\n",
      "16'b1001101010110101,\n",
      "16'b1001000000011100,\n",
      "16'b1001101001100110,\n",
      "16'b1001001110000011,\n",
      "16'b1001001001111010\n",
      "};\n",
      "b_enc_2_var = {\n",
      "16'b1001010110101110\n",
      "};\n",
      "w_enc_3 = {\n",
      "16'b1000010110100100,\n",
      "16'b0101010011011001,\n",
      "16'b1000100111100110,\n",
      "16'b1000100110011101,\n",
      "16'b1000100011001110,\n",
      "16'b0101101010001000\n",
      "};\n",
      "b_enc_3 = {\n",
      "16'b0000000010100000,\n",
      "16'b0000001110101100,\n",
      "16'b1000000001110110,\n",
      "16'b1000001000010001,\n",
      "16'b0000001101011000,\n",
      "16'b0000010011111101\n",
      "};\n"
     ]
    }
   ],
   "source": [
    "# Layer baru\n",
    "import numpy as np\n",
    "\n",
    "# Data untuk setiap layer\n",
    "# Data baru untuk setiap layer\n",
    "z_mean_weights = np.array([\n",
    "    [-1.584273],\n",
    "    [0.81312776],\n",
    "    [-1.252652],\n",
    "    [-2.0995972],\n",
    "    [0.38793242],\n",
    "    [0.9686]\n",
    "])\n",
    "z_mean_biases = np.array([0.26508898])\n",
    "\n",
    "z_var_weights = np.array([\n",
    "    [-2.3098145],\n",
    "    [-2.4394205],\n",
    "    [-3.3002923],\n",
    "    [-2.0141368],\n",
    "    [-3.3384168],\n",
    "    [-2.2930665]\n",
    "])\n",
    "z_var_biases = np.array([-2.7102737])\n",
    "\n",
    "hidden_classifier_weights = np.array([\n",
    "    [11.316853, -1.1008247, -1.2020463, -1.2375807, 10.606073, -0.70532894]\n",
    "])\n",
    "hidden_classifier_biases = np.array([0.6235789, 0.41815737, -0.25837928, -0.05770101, 0.45935965, 0.07813056])\n",
    "\n",
    "classifier_output_weights = np.array([\n",
    "    [2.5071313, -2.8863149],\n",
    "    [-1.1084564, 1.1964823],\n",
    "    [0.43355542, -0.08821499],\n",
    "    [-0.3390887, 0.09997902],\n",
    "    [2.4702315, -2.6811194],\n",
    "    [-0.25160715, 0.8614477]\n",
    "])\n",
    "classifier_output_biases = np.array([0.0016987, -0.00169955])\n",
    "\n",
    "# Flattening the arrays in reverse order\n",
    "flattened_z_mean_weights = z_mean_weights.flatten()[::-1]\n",
    "flattened_z_mean_biases = z_mean_biases.flatten()[::-1]\n",
    "\n",
    "flattened_z_var_weights = z_var_weights.flatten()[::-1]\n",
    "flattened_z_var_biases = z_var_biases.flatten()[::-1]\n",
    "\n",
    "flattened_hidden_classifier_weights = hidden_classifier_weights.flatten()[::-1]\n",
    "flattened_hidden_classifier_biases = hidden_classifier_biases.flatten()[::-1]\n",
    "\n",
    "flattened_classifier_output_weights = classifier_output_weights.flatten()[::-1]\n",
    "flattened_classifier_output_biases = classifier_output_biases.flatten()[::-1]\n",
    "\n",
    "print(\"w_enc_2_mean = {\")\n",
    "for i in range(len(flattened_z_mean_weights)):\n",
    "    if i != len(flattened_z_mean_weights)-1:\n",
    "        print(f\"16'b{float_to_custom_binary(flattened_z_mean_weights[i])},\")\n",
    "    else:\n",
    "        print(f\"16'b{float_to_custom_binary(flattened_z_mean_weights[i])}\")\n",
    "print(\"};\")\n",
    "\n",
    "print(\"b_enc_2_mean = {\")\n",
    "for i in range(len(flattened_z_mean_biases)):\n",
    "    if i != len(flattened_z_mean_biases)-1:\n",
    "        print(f\"16'b{float_to_custom_binary(flattened_z_mean_biases[i])},\")\n",
    "    else:\n",
    "        print(f\"16'b{float_to_custom_binary(flattened_z_mean_biases[i])}\")\n",
    "print(\"};\")\n",
    "\n",
    "print(\"w_enc_2_var = {\")\n",
    "for i in range(len(flattened_z_var_weights)):\n",
    "    if i != len(flattened_z_var_weights)-1:\n",
    "        print(f\"16'b{float_to_custom_binary(flattened_z_var_weights[i])},\")\n",
    "    else:\n",
    "        print(f\"16'b{float_to_custom_binary(flattened_z_var_weights[i])}\")\n",
    "print(\"};\")\n",
    "\n",
    "print(\"b_enc_2_var = {\")\n",
    "for i in range(len(flattened_z_var_biases)):\n",
    "    if i != len(flattened_z_var_biases)-1:\n",
    "        print(f\"16'b{float_to_custom_binary(flattened_z_var_biases[i])},\")\n",
    "    else:\n",
    "        print(f\"16'b{float_to_custom_binary(flattened_z_var_biases[i])}\")\n",
    "print(\"};\")\n",
    "\n",
    "print(\"w_enc_3 = {\")\n",
    "for i in range(len(flattened_hidden_classifier_weights)):\n",
    "    if i != len(flattened_hidden_classifier_weights)-1:\n",
    "        print(f\"16'b{float_to_custom_binary(flattened_hidden_classifier_weights[i])},\")\n",
    "    else:\n",
    "        print(f\"16'b{float_to_custom_binary(flattened_hidden_classifier_weights[i])}\")\n",
    "print(\"};\")\n",
    "\n",
    "print(\"b_enc_3 = {\")\n",
    "for i in range(len(flattened_hidden_classifier_biases)):\n",
    "    if i != len(flattened_hidden_classifier_biases)-1:\n",
    "        print(f\"16'b{float_to_custom_binary(flattened_hidden_classifier_biases[i])},\")\n",
    "    else:\n",
    "        print(f\"16'b{float_to_custom_binary(flattened_hidden_classifier_biases[i])}\")\n",
    "print(\"};\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w_enc_3 = {\n",
      "16'b1000010110100100,\n",
      "16'b0101010011011001,\n",
      "16'b1000100111100110,\n",
      "16'b1000100110011101,\n",
      "16'b1000100011001110,\n",
      "16'b0101101010001000\n",
      "};\n",
      "b_enc_3 = {\n",
      "16'b0000000010100000,\n",
      "16'b0000001110101100,\n",
      "16'b1000000001110110,\n",
      "16'b1000001000010001,\n",
      "16'b0000001101011000,\n",
      "16'b0000010011111101\n",
      "};\n"
     ]
    }
   ],
   "source": [
    "print(\"w_enc_3 = {\")\n",
    "for i in range(len(flattened_hidden_classifier_weights)):\n",
    "    if i != len(flattened_hidden_classifier_weights)-1:\n",
    "        print(f\"16'b{float_to_custom_binary(flattened_hidden_classifier_weights[i])},\")\n",
    "    else:\n",
    "        print(f\"16'b{float_to_custom_binary(flattened_hidden_classifier_weights[i])}\")\n",
    "print(\"};\")\n",
    "\n",
    "print(\"b_enc_3 = {\")\n",
    "for i in range(len(flattened_hidden_classifier_biases)):\n",
    "    if i != len(flattened_hidden_classifier_biases)-1:\n",
    "        print(f\"16'b{float_to_custom_binary(flattened_hidden_classifier_biases[i])},\")\n",
    "    else:\n",
    "        print(f\"16'b{float_to_custom_binary(flattened_hidden_classifier_biases[i])}\")\n",
    "print(\"};\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w_enc_4 = {\n",
      "16'b0000011011100100,\n",
      "16'b1000001000000011,\n",
      "16'b1001010101110010,\n",
      "16'b0001001111000011,\n",
      "16'b0000000011001100,\n",
      "16'b1000001010110110,\n",
      "16'b1000000010110100,\n",
      "16'b0000001101110111,\n",
      "16'b0000100110010010,\n",
      "16'b1000100011011110,\n",
      "16'b1001011100010111,\n",
      "16'b0001010000001110\n",
      "};\n",
      "b_enc_4 = {\n",
      "16'b1000000000000011,\n",
      "16'b0000000000000011\n",
      "};\n"
     ]
    }
   ],
   "source": [
    "print(\"w_enc_4 = {\")\n",
    "for i in range(len(flattened_classifier_output_weights)):\n",
    "    if i != len(flattened_classifier_output_weights)-1:\n",
    "        print(f\"16'b{float_to_custom_binary(flattened_classifier_output_weights[i])},\")\n",
    "    else:\n",
    "        print(f\"16'b{float_to_custom_binary(flattened_classifier_output_weights[i])}\")\n",
    "print(\"};\")\n",
    "\n",
    "print(\"b_enc_4 = {\")\n",
    "for i in range(len(flattened_classifier_output_biases)):\n",
    "    if i != len(flattened_classifier_output_biases)-1:\n",
    "        print(f\"16'b{float_to_custom_binary(flattened_classifier_output_biases[i])},\")\n",
    "    else:\n",
    "        print(f\"16'b{float_to_custom_binary(flattened_classifier_output_biases[i])}\")\n",
    "print(\"};\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
