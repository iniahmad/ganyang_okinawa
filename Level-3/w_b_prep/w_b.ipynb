{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def float_to_custom_binary(float_value):\n",
    "    # Determine the sign bit\n",
    "    sign_bit = 0 if float_value >= 0 else 1\n",
    "\n",
    "    # Get the absolute value of the float for further processing\n",
    "    abs_value = abs(float_value)\n",
    "\n",
    "    # Separate the integer and fractional parts\n",
    "    integer_part = int(abs_value)\n",
    "    fractional_part = abs_value - integer_part\n",
    "\n",
    "    # Convert the integer part to binary (4 bits)\n",
    "    integer_binary = format(integer_part & 0b1111, '04b')\n",
    "\n",
    "    # Convert the fractional part to binary (27 bits)\n",
    "    fractional_binary = ''\n",
    "    for _ in range(11):\n",
    "        fractional_part *= 2\n",
    "        bit = int(fractional_part)\n",
    "        fractional_binary += str(bit)\n",
    "        fractional_part -= bit\n",
    "\n",
    "    # Combine all parts into a single binary string\n",
    "    custom_binary = f\"{sign_bit}{integer_binary}{fractional_binary}\"\n",
    "\n",
    "    return custom_binary\n",
    "\n",
    "def binary_to_float(binary_str):\n",
    "    \"\"\"Convert a 32-bit binary string to a float.\"\"\"\n",
    "    sign = int(binary_str[0])\n",
    "    integer_part = int(binary_str[1:5], 2)\n",
    "    fractional_part = binary_str[5:]\n",
    "    frac_value = 0.0\n",
    "    for i, bit in enumerate(fractional_part):\n",
    "        if bit == '1':\n",
    "            frac_value += 1 / (2 ** (i + 1))\n",
    "    float_value = integer_part + frac_value\n",
    "    if sign == 1:\n",
    "        float_value = -float_value\n",
    "    return float_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "// Testcase 22 False\n",
      "x = {\n",
      "16'b0000001101010011,\n",
      "16'b0000001101001001,\n",
      "16'b0000010001101110,\n",
      "16'b0000001110101001,\n",
      "16'b0000001110010101,\n",
      "16'b0000010000010001,\n",
      "16'b0000010011000001,\n",
      "16'b0000010100010000,\n",
      "16'b0000001110001110,\n",
      "16'b0000001110010101\n",
      "};\n",
      "\n",
      "#600;\n",
      "reset = 1;\n",
      "x = 0;\n",
      "// Wait for global reset to finish\n",
      "#10;\n",
      "reset = 0;\n",
      "\n",
      "// Testcase 23 False\n",
      "x = {\n",
      "16'b0000010111111100,\n",
      "16'b0000010111101000,\n",
      "16'b0000010101100100,\n",
      "16'b0000011001011111,\n",
      "16'b0000010110111010,\n",
      "16'b0000011000101010,\n",
      "16'b0000011001100110,\n",
      "16'b0000011001010010,\n",
      "16'b0000011000010000,\n",
      "16'b0000010111111100\n",
      "};\n",
      "\n",
      "#600;\n",
      "reset = 1;\n",
      "x = 0;\n",
      "// Wait for global reset to finish\n",
      "#10;\n",
      "reset = 0;\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Testbench data\n",
    "import numpy as np\n",
    "\n",
    "# Define the values as a 2D NumPy array\n",
    "values = np.array([\n",
    "    [0.52158273, 0.24820144, 0.79676259, 0.55035971, 0.52697842, 0.16366906, 0.16546763, 0.73920863, 0.46402878, 0.34352518],\n",
    "    [0.55555556, 0.46296296, 0.41077441, 0.42760943, 0.33501684, 0.57575758, 0.33164983, 0.52356902, 0.44949495, 0.42760943],\n",
    "    [0.73218673, 0.75675676, 0.74692875, 0.72727273, 0.71007371, 0.70761671, 0.69041769, 0.71498771, 0.72481572, 0.75429975],\n",
    "    [0.41613924, 0.35601266, 0.36392405, 0.3971519,  0.3528481,  0.36234177, 0.38132911, 0.27531646, 0.54588608, 0.40981013],\n",
    "    [0.46638655, 0.79621849, 0.36344538, 0.71848739, 0.41806723, 0.3802521,  0.3802521,  0.59033613, 0.57352941, 0.60504202],\n",
    "    [0.7002457,  0.66093366, 0.66830467, 0.74447174, 0.75184275, 0.68550369, 0.6953317,  0.7002457,  0.71007371, 0.65847666],\n",
    "    [0.54871795, 0.34358974, 1.0,        0.74102564, 0.72564103, 0.46923077, 0.94871795, 0.74102564, 0.73333333, 0.46410256],\n",
    "    [0.54411765, 0.48109244, 0.39705882, 0.57563025, 0.22268908, 0.22478992, 0.91176471, 0.41806723, 0.71428571, 0.44327731],\n",
    "    [0.78343949, 0.78343949, 0.69002123, 0.68577495, 0.74309979, 0.75159236, 0.73460722, 0.66878981, 0.74734607, 0.78768577],\n",
    "    [0.75776398, 0.73913043, 0.72049689, 0.77329193, 0.76397516, 0.7484472,  0.72981366, 0.7484472,  0.73602484, 0.75776398],\n",
    "    [0.18642351, 0.26342452, 0.23100304, 0.22087133, 0.20364742, 0.32826748, 0.20263425, 0.26342452, 0.22695035, 0.19756839],\n",
    "    [0.37025316, 0.38449367, 0.13765823, 0.13765823, 0.53639241, 0.42088608, 0.16297468, 0.10126582, 0.44303797, 0.47310127],\n",
    "    [0.74927954, 0.74639769, 0.74063401, 0.74351585, 0.77233429, 0.74063401, 0.75216138, 0.73198847, 0.72910663, 0.74063401],\n",
    "    [0.61663286, 0.62677485, 0.61866126, 0.62677485, 0.62271805, 0.62474645, 0.64908722, 0.55578093, 0.67951318, 0.65517241],\n",
    "    [0.37668919, 0.6875,     0.36824324, 0.63851351, 0.47635135, 0.43918919, 0.47972973, 0.58952703, 0.54898649, 0.55574324],\n",
    "    [0.7173913,  0.70496894, 0.71118012, 0.69254658, 0.72049689, 0.72360248, 0.71118012, 0.69254658, 0.70496894, 0.70807453],\n",
    "    [0.77616279, 0.61337209, 0.59302326, 0.60174419, 0.59011628, 0.59593023, 0.38953488, 0.7994186,  0.55232558, 0.64534884],\n",
    "    [0.72542373, 0.73898305, 0.71355932, 0.6779661,  0.68305085, 0.71864407, 0.73389831, 0.7,        0.67118644, 0.68135593],\n",
    "    [0.34810127, 0.40031646, 0.37341772, 0.35601266, 0.36867089, 0.46044304, 0.42088608, 0.52689873, 0.34018987, 0.3528481 ],\n",
    "    [0.6953317,  0.6977887,  0.72727273, 0.73710074, 0.74692875, 0.71253071, 0.69041769, 0.68796069, 0.6953317,  0.71498771],\n",
    "    [0.61038961, 0.59253247, 0.61688312, 0.61850649, 0.58441558, 0.61525974, 0.60227273, 0.90097403, 0.46266234, 0.67857143],\n",
    "    [0.6879562,  0.68430657, 0.80291971, 0.85218978, 0.82664234, 0.89416058, 0.85218978, 0.72627737, 0.79562044, 0.79379562],\n",
    "    [0.41582492, 0.41077441, 0.55387205, 0.45791246, 0.44781145, 0.50841751, 0.59427609, 0.63299663, 0.44444444, 0.44781145],\n",
    "    [0.7483871,  0.73870968, 0.67419355, 0.79677419, 0.71612903, 0.77096774, 0.8,        0.79032258, 0.75806452, 0.7483871 ],\n",
    "    [0.76080692, 0.75504323, 0.75504323, 0.77809798, 0.76945245, 0.76080692, 0.76657061, 0.78962536, 0.78386167, 0.74639769],\n",
    "    [0.57627119, 0.55932203, 0.51412429, 0.51694915, 0.52259887, 0.50847458, 0.52542373, 0.52542373, 0.56497175, 0.46045198],\n",
    "    [0.55367232, 0.56214689, 0.57062147, 0.58474576, 0.57062147, 0.55367232, 0.53107345, 0.51977401, 0.52259887, 0.53954802],\n",
    "    [0.33227848, 0.47151899, 0.38449367, 0.48575949, 0.33702532, 0.33227848, 0.31487342, 0.33544304, 0.39240506, 0.4335443 ],\n",
    "    [0.63081395, 0.60465116, 0.61046512, 0.5872093,  0.61046512, 0.55232558, 0.6627907,  0.62209302, 0.41569767, 0.7994186 ],\n",
    "    [0.73602484, 0.7515528,  0.76397516, 0.73913043, 0.72981366, 0.74534161, 0.76708075, 0.73913043, 0.71118012, 0.72049689],\n",
    "    [0.76340111, 0.36044362, 0.33456562, 0.42513863, 0.38632163, 0.55268022, 0.56931608, 0.64140481, 0.3844732,  0.90018484],\n",
    "    [0.19763514, 0.39864865, 0.22804054, 0.53547297, 0.49662162, 0.27195946, 0.4222973,  0.47635135, 0.3125,     0.39189189],\n",
    "    [0.60521042, 0.65330661, 0.68937876, 0.71142285, 0.66933868, 0.66933868, 0.67134269, 0.63927856, 0.59719439, 0.63527054],\n",
    "    [0.82066869, 0.81458967, 0.82066869, 0.82978723, 0.85714286, 0.87537994, 0.86930091, 0.84802432, 0.87234043, 0.89057751],\n",
    "    [0.6753507,  0.70140281, 0.7755511,  0.68537074, 0.68537074, 0.74549098, 0.86573146, 0.73547094, 0.72344689, 0.77154309],\n",
    "    [0.72360248, 0.7484472,  0.76086957, 0.74223602, 0.72360248, 0.73291925, 0.73602484, 0.75776398, 0.76708075, 0.72981366],\n",
    "    [0.61411765, 0.18352941, 0.31529412, 0.70117647, 0.53176471, 0.68235294, 0.56235294, 0.61882353, 0.55529412, 0.62588235],\n",
    "    [0.61016949, 0.56214689, 0.5480226,  0.51412429, 0.51129944, 0.51694915, 0.53672316, 0.55649718, 0.57627119, 0.60169492],\n",
    "    [0.33641405, 0.34195933, 0.75970425, 0.29205176, 0.72828096, 0.32532348, 0.72643253, 0.37338262, 0.69316081, 0.34750462],\n",
    "    [0.5990099,  0.60148515, 0.59158416, 0.58168317, 0.59158416, 0.61138614, 0.58663366, 0.58415842, 0.58168317, 0.59653465],\n",
    "    [0.78115502, 0.76899696, 0.75379939, 0.79027356, 0.78723404, 0.78115502, 0.76291793, 0.78723404, 0.7781155,  0.78115502],\n",
    "    [0.71142285, 0.74148297, 0.75150301, 0.74148297, 0.67735471, 0.78156313, 0.8256513,  0.76553106, 0.62925852, 0.63126253],\n",
    "    [0.71342685, 0.75751503, 0.76553106, 0.68136273, 0.61122244, 0.69739479, 0.78557114, 0.80761523, 0.72745491, 0.74348697],\n",
    "    [0.36603774, 0.90377358, 0.36792453, 0.89433962, 0.36415094, 0.90754717, 0.36792453, 0.44150943, 0.44339623, 0.61698113],\n",
    "    [0.69487179, 0.71025641, 0.71282051, 0.7,        0.70512821, 0.71538462, 0.69487179, 0.70512821, 0.68461538, 0.68205128],\n",
    "    [0.90732759, 0.89224138, 0.92456897, 0.92025862, 0.89655172, 0.93318966, 0.89655172, 0.91163793, 0.89008621, 0.90732759],\n",
    "    [0.75373134, 0.76119403, 0.7960199,  0.83333333, 0.83084577, 0.78358209, 0.76368159, 0.79353234, 0.82587065, 0.82587065],\n",
    "    [0.97966728, 0.78743068, 0.34935305, 0.31608133, 0.92606285, 0.80036969, 0.37707948, 0.33826248, 0.95563771, 0.7689464 ],\n",
    "    [0.60380952, 0.61333333, 0.6,        0.58666667, 0.59619048, 0.60761905, 0.58095238, 0.5752381,  0.59238095, 0.58095238],\n",
    "    [0.41694915, 0.38305085, 0.31355932, 0.47966102, 0.48813559, 0.51186441, 0.3,        0.51355932, 0.27966102, 0.54067797],\n",
    "    [0.88865546, 0.48529412, 0.72268908, 0.46008403, 0.56932773, 0.37815126, 0.67226891, 0.45378151, 0.61554622, 0.45168067],\n",
    "    [0.21790541, 0.41722973, 0.42905405, 0.42398649, 0.25168919, 0.72466216, 0.25337838, 0.46452703, 0.42567568, 0.375],\n",
    "    [0.7960199, 0.76119403, 0.77363184, 0.76616915, 0.8159204, 0.80845771, 0.83333333, 0.82338308, 0.76119403, 0.7761194],\n",
    "    [0.47058824, 0.52521008, 0.20378151, 0.20378151, 0.55042017, 0.4012605, 0.5987395, 0.4012605, 0.5987395, 0.43277311],\n",
    "    [0.31864407, 0.47966102, 0.43559322, 0.63898305, 0.3440678, 0.3440678, 0.33389831, 0.36610169, 0.46610169, 0.37288136],\n",
    "    [0.57176471, 0.61647059, 0.57176471, 0.57176471, 0.56470588, 0.58117647, 0.57411765, 0.58117647, 0.57176471, 0.57176471],\n",
    "    [0.72981366, 0.7173913, 0.71118012, 0.69565217, 0.70807453, 0.70186335, 0.72360248, 0.73602484, 0.70186335, 0.69565217],\n",
    "    [0.57425743, 0.58415842, 0.57673267, 0.59653465, 0.5990099, 0.58910891, 0.56683168, 0.57673267, 0.58910891, 0.58910891],\n",
    "    [0.73291925, 0.73913043, 0.7515528, 0.75776398, 0.75776398, 0.74223602, 0.73602484, 0.74534161, 0.77329193, 0.7515528],\n",
    "    [0.72399151, 0.83014862, 0.71549894, 0.69426752, 0.77494692, 0.75583864, 0.67515924, 0.63269639, 0.72186837, 0.7133758],\n",
    "    [0.22972973, 0.21283784, 0.45608108, 0.26013514, 0.3277027, 0.36993243, 0.36655405, 0.41891892, 0.28040541, 0.26689189],\n",
    "    [0.51495017, 0.25913621, 0.54152824, 0.25249169, 0.53156146, 0.24031008, 0.53156146, 0.26356589, 0.54263566, 0.24806202],\n",
    "    [0.65605096, 0.67303609, 0.69214437, 0.67728238, 0.72399151, 0.88747346, 0.80467091, 0.79193206, 0.75583864, 0.72186837],\n",
    "    [0.4040404, 0.47474747, 0.53198653, 0.53198653, 0.52861953, 0.55555556, 0.41919192, 0.46296296, 0.39225589, 0.4983165],\n",
    "    [0.70761671, 0.70515971, 0.68796069, 0.74692875, 0.76412776, 0.68304668, 0.66584767, 0.7002457, 0.72235872, 0.71990172],\n",
    "    [0.71935484, 0.71935484, 0.69677419, 0.73225806, 0.77741935, 0.78709677, 0.7516129, 0.73225806, 0.73548387, 0.74193548],\n",
    "    [0.75216138, 0.73487032, 0.76945245, 0.74351585, 0.76080692, 0.77521614, 0.76080692, 0.76080692, 0.78097983, 0.77233429],\n",
    "    [0.57116451, 0.62292052, 0.63770795, 0.60073937, 0.56931608, 0.5767098, 0.59149723, 0.62661738, 0.66543438, 0.66543438],\n",
    "    [0.78957916, 0.7254509, 0.65931864, 0.79158317, 0.76753507, 0.70140281, 0.76352705, 0.749499, 0.78557114, 0.71142285],\n",
    "    [0.77124183, 0.76034858, 0.81045752, 0.81917211, 0.79956427, 0.78649237, 0.77124183, 0.76688453, 0.78867102, 0.85185185],\n",
    "    [0.23708207, 0.22796353, 0.18439716, 0.26342452, 0.20263425, 0.21175279, 0.21783181, 0.2147923, 0.25937183, 0.22593718],\n",
    "    [0.52129817, 0.32048682, 0.30831643, 0.34482759, 0.3346856, 0.29614604, 0.45436105, 0.36105477, 0.37728195, 0.43610548],\n",
    "    [0.52259887, 0.56497175, 0.5480226, 0.58474576, 0.57344633, 0.57344633, 0.51412429, 0.52259887, 0.50564972, 0.52542373],\n",
    "    [0.80748663, 0.81550802, 0.86363636, 0.86363636, 0.86096257, 0.79144385, 0.76203209, 0.7459893, 0.77540107, 0.83957219],\n",
    "    [0.71118012, 0.72670807, 0.7173913, 0.74223602, 0.73291925, 0.73291925, 0.70807453, 0.7484472, 0.73913043, 0.72981366],\n",
    "    [0.8453159, 0.8540305, 0.78867102, 0.80392157, 0.79084967, 0.79302832, 0.81699346, 0.85185185, 0.83224401, 0.77342048],\n",
    "    [0.78723404, 0.81458967, 0.79635258, 0.80243161, 0.81155015, 0.83282675, 0.7993921, 0.80547112, 0.81155015, 0.81155015],\n",
    "    [0.60377358, 0.6, 0.60566038, 0.61132075, 0.59622642, 0.58867925, 0.61320755, 0.61132075, 0.59433962, 0.61320755],\n",
    "    [0.57647059, 0.57882353, 0.59764706, 0.58352941, 0.56941176, 0.56, 0.58117647, 0.58117647, 0.58352941, 0.40705882],\n",
    "    [0.20567376, 0.26443769, 0.22695035, 0.2077001, 0.14488349, 0.14488349, 0.2289767, 0.18439716, 0.17933131, 0.30800405]\n",
    "])\n",
    "\n",
    "boolean_values = np.array([\n",
    "    True, False, False, True, True, False, True, True, False, False,\n",
    "    True, True, False, False, True, False, True, False, False, False,\n",
    "    False, False, False, False, False, False, False, False, True, False,\n",
    "    True, True, False, False, False, False, True, False, True, False,\n",
    "    False, False, False, True, False, False, False, True, False, False,\n",
    "    True, True, False, True, False, False, False, False, False, False,\n",
    "    True, True, False, False, False, False, False, False, False, False,\n",
    "    True, False, False, False, False, False, False, False, False, True\n",
    "])\n",
    "\n",
    "# True label (urut atas ke bawah)\n",
    "'''\n",
    "0True\n",
    "1False\n",
    "2False\n",
    "3True\n",
    "4True\n",
    "5False\n",
    "6True\n",
    "7True\n",
    "8False\n",
    "False\n",
    "True\n",
    "True\n",
    "False\n",
    "False\n",
    "True\n",
    "False\n",
    "True\n",
    "False\n",
    "False\n",
    "False\n",
    "False\n",
    "False\n",
    "False\n",
    "False\n",
    "False\n",
    "False\n",
    "False\n",
    "False\n",
    "True\n",
    "False\n",
    "'''\n",
    "index_up = 22\n",
    "print(f\"// Testcase {index_up} {boolean_values[index_up]}\")\n",
    "print(\"x = {\")\n",
    "val0 = values[index_up]\n",
    "for i in range(len(val0)):\n",
    "    if i != len(val0)-1:\n",
    "        print(f\"16'b{float_to_custom_binary(val0[i])},\")\n",
    "    else:\n",
    "        print(f\"16'b{float_to_custom_binary(val0[i])}\")\n",
    "print(\"};\")\n",
    "print('''\n",
    "#600;\n",
    "reset = 1;\n",
    "x = 0;\n",
    "// Wait for global reset to finish\n",
    "#10;\n",
    "reset = 0;\n",
    "''')\n",
    "\n",
    "index_down = 23\n",
    "print(f\"// Testcase {index_down} {boolean_values[index_up]}\")\n",
    "print(\"x = {\")\n",
    "val1 = values[index_down]\n",
    "for i in range(len(val1)):\n",
    "    if i != len(val1)-1:\n",
    "        print(f\"16'b{float_to_custom_binary(val1[i])},\")\n",
    "    else:\n",
    "        print(f\"16'b{float_to_custom_binary(val1[i])}\")\n",
    "print(\"};\")\n",
    "print('''\n",
    "#600;\n",
    "reset = 1;\n",
    "x = 0;\n",
    "// Wait for global reset to finish\n",
    "#10;\n",
    "reset = 0;\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "// Testcase 71 False\n",
      "test_index = 16'd71;\n",
      "x = {\n",
      "16'b0000010000101011,\n",
      "16'b0000001010010000,\n",
      "16'b0000001001110111,\n",
      "16'b0000001011000010,\n",
      "16'b0000001010101101,\n",
      "16'b0000001001011110,\n",
      "16'b0000001110100010,\n",
      "16'b0000001011100011,\n",
      "16'b0000001100000100,\n",
      "16'b0000001101111101\n",
      "};\n",
      "true_label = 0;\n",
      "\n",
      "    #600;\n",
      "    reset = 1;\n",
      "    x = 0;\n",
      "    // Wait for global reset to finish\n",
      "    #10;\n",
      "    reset = 0;\n",
      "    \n",
      "// Testcase 72 False\n",
      "test_index = 16'd72;\n",
      "x = {\n",
      "16'b0000010000101110,\n",
      "16'b0000010010000101,\n",
      "16'b0000010001100010,\n",
      "16'b0000010010101101,\n",
      "16'b0000010010010110,\n",
      "16'b0000010010010110,\n",
      "16'b0000010000011100,\n",
      "16'b0000010000101110,\n",
      "16'b0000010000001011,\n",
      "16'b0000010000110100\n",
      "};\n",
      "true_label = 0;\n",
      "\n",
      "    #600;\n",
      "    reset = 1;\n",
      "    x = 0;\n",
      "    // Wait for global reset to finish\n",
      "    #10;\n",
      "    reset = 0;\n",
      "    \n",
      "// Testcase 73 False\n",
      "test_index = 16'd73;\n",
      "x = {\n",
      "16'b0000011001110101,\n",
      "16'b0000011010000110,\n",
      "16'b0000011011101000,\n",
      "16'b0000011011101000,\n",
      "16'b0000011011100011,\n",
      "16'b0000011001010100,\n",
      "16'b0000011000011000,\n",
      "16'b0000010111110111,\n",
      "16'b0000011000110100,\n",
      "16'b0000011010110111\n",
      "};\n",
      "true_label = 0;\n",
      "\n",
      "    #600;\n",
      "    reset = 1;\n",
      "    x = 0;\n",
      "    // Wait for global reset to finish\n",
      "    #10;\n",
      "    reset = 0;\n",
      "    \n",
      "// Testcase 74 False\n",
      "test_index = 16'd74;\n",
      "x = {\n",
      "16'b0000010110110000,\n",
      "16'b0000010111010000,\n",
      "16'b0000010110111101,\n",
      "16'b0000010111110000,\n",
      "16'b0000010111011101,\n",
      "16'b0000010111011101,\n",
      "16'b0000010110101010,\n",
      "16'b0000010111111100,\n",
      "16'b0000010111101001,\n",
      "16'b0000010111010110\n",
      "};\n",
      "true_label = 0;\n",
      "\n",
      "    #600;\n",
      "    reset = 1;\n",
      "    x = 0;\n",
      "    // Wait for global reset to finish\n",
      "    #10;\n",
      "    reset = 0;\n",
      "    \n",
      "// Testcase 75 False\n",
      "test_index = 16'd75;\n",
      "x = {\n",
      "16'b0000011011000011,\n",
      "16'b0000011011010101,\n",
      "16'b0000011001001111,\n",
      "16'b0000011001101110,\n",
      "16'b0000011001010011,\n",
      "16'b0000011001011000,\n",
      "16'b0000011010001001,\n",
      "16'b0000011011010000,\n",
      "16'b0000011010101000,\n",
      "16'b0000011000101111\n",
      "};\n",
      "true_label = 0;\n",
      "\n",
      "    #600;\n",
      "    reset = 1;\n",
      "    x = 0;\n",
      "    // Wait for global reset to finish\n",
      "    #10;\n",
      "    reset = 0;\n",
      "    \n",
      "// Testcase 76 False\n",
      "test_index = 16'd76;\n",
      "x = {\n",
      "16'b0000011001001100,\n",
      "16'b0000011010000100,\n",
      "16'b0000011001011110,\n",
      "16'b0000011001101011,\n",
      "16'b0000011001111110,\n",
      "16'b0000011010101001,\n",
      "16'b0000011001100101,\n",
      "16'b0000011001110001,\n",
      "16'b0000011001111110,\n",
      "16'b0000011001111110\n",
      "};\n",
      "true_label = 0;\n",
      "\n",
      "    #600;\n",
      "    reset = 1;\n",
      "    x = 0;\n",
      "    // Wait for global reset to finish\n",
      "    #10;\n",
      "    reset = 0;\n",
      "    \n",
      "// Testcase 77 False\n",
      "test_index = 16'd77;\n",
      "x = {\n",
      "16'b0000010011010100,\n",
      "16'b0000010011001100,\n",
      "16'b0000010011011000,\n",
      "16'b0000010011100011,\n",
      "16'b0000010011000101,\n",
      "16'b0000010010110101,\n",
      "16'b0000010011100111,\n",
      "16'b0000010011100011,\n",
      "16'b0000010011000001,\n",
      "16'b0000010011100111\n",
      "};\n",
      "true_label = 0;\n",
      "\n",
      "    #600;\n",
      "    reset = 1;\n",
      "    x = 0;\n",
      "    // Wait for global reset to finish\n",
      "    #10;\n",
      "    reset = 0;\n",
      "    \n",
      "// Testcase 78 False\n",
      "test_index = 16'd78;\n",
      "x = {\n",
      "16'b0000010010011100,\n",
      "16'b0000010010100001,\n",
      "16'b0000010011000111,\n",
      "16'b0000010010101011,\n",
      "16'b0000010010001110,\n",
      "16'b0000010001111010,\n",
      "16'b0000010010100110,\n",
      "16'b0000010010100110,\n",
      "16'b0000010010101011,\n",
      "16'b0000001101000001\n",
      "};\n",
      "true_label = 0;\n",
      "\n",
      "    #600;\n",
      "    reset = 1;\n",
      "    x = 0;\n",
      "    // Wait for global reset to finish\n",
      "    #10;\n",
      "    reset = 0;\n",
      "    \n",
      "// Testcase 79 True\n",
      "test_index = 16'd79;\n",
      "x = {\n",
      "16'b0000000110100101,\n",
      "16'b0000001000011101,\n",
      "16'b0000000111010000,\n",
      "16'b0000000110101001,\n",
      "16'b0000000100101000,\n",
      "16'b0000000100101000,\n",
      "16'b0000000111010100,\n",
      "16'b0000000101111001,\n",
      "16'b0000000101101111,\n",
      "16'b0000001001110110\n",
      "};\n",
      "true_label = 1;\n",
      "\n",
      "    #600;\n",
      "    reset = 1;\n",
      "    x = 0;\n",
      "    // Wait for global reset to finish\n",
      "    #10;\n",
      "    reset = 0;\n",
      "    \n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 80 is out of bounds for axis 0 with size 80",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[47], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m index \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m71\u001b[39m,\u001b[38;5;241m81\u001b[39m):\n\u001b[1;32m----> 2\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m// Testcase \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mindex\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mboolean_values\u001b[49m\u001b[43m[\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_index = 16\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124md\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mindex\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m;\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx = \u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mIndexError\u001b[0m: index 80 is out of bounds for axis 0 with size 80"
     ]
    }
   ],
   "source": [
    "for index in range(71,80):\n",
    "    print(f\"// Testcase {index} {boolean_values[index]}\")\n",
    "    print(f\"test_index = 16'd{index};\")\n",
    "    print(\"x = {\")\n",
    "    val0 = values[index]\n",
    "    for i in range(len(val0)):\n",
    "        if i != len(val0)-1:\n",
    "            print(f\"16'b{float_to_custom_binary(val0[i])},\")\n",
    "        else:\n",
    "            print(f\"16'b{float_to_custom_binary(val0[i])}\")\n",
    "    print(\"};\")\n",
    "    if boolean_values[index] == True:\n",
    "        print(\"true_label = 1;\")\n",
    "    else:\n",
    "        print(\"true_label = 0;\")\n",
    "    print('''\n",
    "    #600;\n",
    "    reset = 1;\n",
    "    x = 0;\n",
    "    // Wait for global reset to finish\n",
    "    #10;\n",
    "    reset = 0;\n",
    "    ''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w_enc_1 = {\n",
      "16'b0000010110011111,\n",
      "16'b0000101110011011,\n",
      "16'b0000011111000001,\n",
      "16'b0000010000011011,\n",
      "16'b0000000110000010,\n",
      "16'b0000010000101001,\n",
      "16'b1000001001011001,\n",
      "16'b1000000101011110,\n",
      "16'b1000000000010110,\n",
      "16'b1000000110010100,\n",
      "16'b0000000000110111,\n",
      "16'b1000000010001001,\n",
      "16'b0000100010011011,\n",
      "16'b0000100001000110,\n",
      "16'b0000001111110011,\n",
      "16'b0000001011111101,\n",
      "16'b1000001010010000,\n",
      "16'b0000000110010001,\n",
      "16'b1000100110001000,\n",
      "16'b0000011000001010,\n",
      "16'b1001000110001111,\n",
      "16'b0000000000111111,\n",
      "16'b0001001011010100,\n",
      "16'b0000000110000111,\n",
      "16'b0000110101000011,\n",
      "16'b1000000001000000,\n",
      "16'b0000110011100001,\n",
      "16'b1000000100110000,\n",
      "16'b1001000100011110,\n",
      "16'b1000000101111011,\n",
      "16'b1001001100011100,\n",
      "16'b0000000000011001,\n",
      "16'b0000001101011111,\n",
      "16'b1000001001100011,\n",
      "16'b0000100011000110,\n",
      "16'b1000001000001100,\n",
      "16'b0001100111011010,\n",
      "16'b0000001101001100,\n",
      "16'b1000011101110111,\n",
      "16'b0000001010001001,\n",
      "16'b1000101100101110,\n",
      "16'b0000000000111010,\n",
      "16'b1000110110110110,\n",
      "16'b1000000011001010,\n",
      "16'b1000001001010111,\n",
      "16'b0000000001010010,\n",
      "16'b0000100111001010,\n",
      "16'b1000000101100000,\n",
      "16'b0000001111011100,\n",
      "16'b1000000100000010,\n",
      "16'b0000111111101001,\n",
      "16'b1000000110100001,\n",
      "16'b1000110100100100,\n",
      "16'b1000000111101011,\n",
      "16'b1000010111100011,\n",
      "16'b0000010001001100,\n",
      "16'b1000100111110110,\n",
      "16'b0000000001010001,\n",
      "16'b0000110001010110,\n",
      "16'b0000000110101010\n",
      "};\n",
      "b_enc_1 = {\n",
      "16'b1000010010110110,\n",
      "16'b0000010101100010,\n",
      "16'b1000010111010110,\n",
      "16'b0000010011110011,\n",
      "16'b1000001110111001,\n",
      "16'b0000000010110110\n",
      "};\n",
      "w_enc_2_mean = {\n",
      "16'b0000110111100110,\n",
      "16'b1000010101001000,\n",
      "16'b0000101111111100,\n",
      "16'b1000001110011100,\n",
      "16'b0001001011010100,\n",
      "16'b1000011101100101\n",
      "};\n",
      "b_enc_2_mean = {\n",
      "16'b1000001100011011\n",
      "};\n",
      "w_enc_2_var = {\n",
      "16'b1001011010111011,\n",
      "16'b1001100001010010,\n",
      "16'b1000111111110111,\n",
      "16'b1010000100011110,\n",
      "16'b1001001010111011,\n",
      "16'b1001001001101101\n",
      "};\n",
      "b_enc_2_var = {\n",
      "16'b1001011101001011\n",
      "};\n",
      "w_enc_3 = {\n",
      "16'b0000100100010001,\n",
      "16'b0000101000000110,\n",
      "16'b1000000001000101,\n",
      "16'b1100001011001001,\n",
      "16'b1110010101110001,\n",
      "16'b0000100000000100\n",
      "};\n",
      "b_enc_3 = {\n",
      "16'b0000001000000001,\n",
      "16'b0000001000110010,\n",
      "16'b1000100100001011,\n",
      "16'b1000000011100110,\n",
      "16'b0000011000111010,\n",
      "16'b0000000011001001\n",
      "};\n",
      "w_enc_4 = {\n",
      "16'b0000010100110111,\n",
      "16'b1000011010101101,\n",
      "16'b0000001111111000,\n",
      "16'b1000001111111011,\n",
      "16'b0000001001111110,\n",
      "16'b0000010010101010,\n",
      "16'b1000100001010111,\n",
      "16'b0000010110101110,\n",
      "16'b1001100100011111,\n",
      "16'b0001100011001111,\n",
      "16'b0000000000010110,\n",
      "16'b1000011111101111\n",
      "};\n",
      "b_enc_4 = {\n",
      "16'b1000000011010110,\n",
      "16'b0000000011010110\n",
      "};\n"
     ]
    }
   ],
   "source": [
    "# New Weight and Bias\n",
    "import numpy as np\n",
    "\n",
    "# Intermediate Layer\n",
    "intermediate_layer_weights = np.array([\n",
    "    [ 0.20803504,  1.5420146,   0.03992786, -1.2453849,   0.5374099,  -0.73605186],\n",
    "    [-0.23981877, -1.6428081,  -0.20402765,  1.9891608,  -0.12619972,  0.4824725 ],\n",
    "    [-0.17192963,  1.2239592,   0.04051813, -0.29292646, -0.09901846, -1.714163  ],\n",
    "    [ 0.02873355, -1.3974937,   0.3170162,  -0.93346524,  0.41243255,  3.2317638 ],\n",
    "    [-0.25590032,  1.0968574,  -0.29863435,  0.4216783,   0.01225645, -2.3889375 ],\n",
    "    [-0.1854569,  -2.1398895,  -0.14853258,  1.610236,   -0.03131349,  1.6577628 ],\n",
    "    [ 0.19129439,  2.3537693,   0.03114566, -2.194876,    0.7550451,  -1.1915832 ],\n",
    "    [ 0.19612038, -0.3205303,   0.37379503,  0.49412403,  1.0341963,   1.0757153 ],\n",
    "    [-0.06726161,  0.02711033, -0.19734114, -0.01099776, -0.17127734, -0.2938378 ],\n",
    "    [ 0.5203593,   0.18887842,  0.51364803,  0.96933615,  1.4508771,   0.70291793]\n",
    "])\n",
    "intermediate_layer_biases = np.array([ 0.08914003, -0.46571058,  0.6189324,  -0.72961104,  0.67298925, -0.5892861 ])\n",
    "\n",
    "# z_mean Layer\n",
    "z_mean_weights = np.array([\n",
    "    [-0.924493 ],\n",
    "    [ 2.3539457],\n",
    "    [-0.4513165],\n",
    "    [ 1.4983582],\n",
    "    [-0.6601875],\n",
    "    [ 1.7374454]\n",
    "])\n",
    "z_mean_biases = np.array([-0.38865975])\n",
    "\n",
    "# z_var Layer\n",
    "z_var_weights = np.array([\n",
    "    [-2.3034732],\n",
    "    [-2.3413618],\n",
    "    [-4.139716 ],\n",
    "    [-1.9957688],\n",
    "    [-3.0401134],\n",
    "    [-2.841663 ]\n",
    "])\n",
    "z_var_biases = np.array([-2.9117427])\n",
    "\n",
    "# Hidden Classifier Layer\n",
    "hidden_classifier_weights = np.array([\n",
    "    [ 1.0024222, -12.680572, -8.348365, -0.03413833, 1.2530577, 1.1333472]\n",
    "])\n",
    "hidden_classifier_biases = np.array([ 0.0985736,  0.7785724, -0.11278027, -1.1308199,  0.27466628, 0.25051776])\n",
    "\n",
    "# Classifier Output Layer\n",
    "classifier_output_weights = np.array([\n",
    "    [-0.9918589,   0.01114055],\n",
    "    [ 3.1014323,  -3.140409  ],\n",
    "    [ 0.7103192,  -1.0428302 ],\n",
    "    [ 0.58318675,  0.31189114],\n",
    "    [-0.49776682,  0.4962351 ],\n",
    "    [-0.8345416,   0.65199584]\n",
    "])\n",
    "classifier_output_biases = np.array([ 0.10454176, -0.10454245])\n",
    "\n",
    "flattened_intermediate_layer_weights = intermediate_layer_weights.flatten()[::-1]\n",
    "flattened_intermediate_layer_biases = intermediate_layer_biases.flatten()[::-1]\n",
    "\n",
    "# Flattening the arrays in reverse order\n",
    "flattened_z_mean_weights = z_mean_weights.flatten()[::-1]\n",
    "flattened_z_mean_biases = z_mean_biases.flatten()[::-1]\n",
    "\n",
    "flattened_z_var_weights = z_var_weights.flatten()[::-1]\n",
    "flattened_z_var_biases = z_var_biases.flatten()[::-1]\n",
    "\n",
    "flattened_hidden_classifier_weights = hidden_classifier_weights.flatten()[::-1]\n",
    "flattened_hidden_classifier_biases = hidden_classifier_biases.flatten()[::-1]\n",
    "\n",
    "flattened_classifier_output_weights = classifier_output_weights.flatten()[::-1]\n",
    "flattened_classifier_output_biases = classifier_output_biases.flatten()[::-1]\n",
    "\n",
    "# Print arrays for verification\n",
    "print(\"w_enc_1 = {\")\n",
    "for i in range(len(flattened_intermediate_layer_weights)):\n",
    "    if i != len(flattened_intermediate_layer_weights)-1:\n",
    "        print(f\"16'b{float_to_custom_binary(flattened_intermediate_layer_weights[i])},\")\n",
    "    else:\n",
    "        print(f\"16'b{float_to_custom_binary(flattened_intermediate_layer_weights[i])}\")\n",
    "print(\"};\")    \n",
    "\n",
    "print(\"b_enc_1 = {\")\n",
    "for i in range(len(flattened_intermediate_layer_biases)):\n",
    "    if i != len(flattened_intermediate_layer_biases)-1:\n",
    "        print(f\"16'b{float_to_custom_binary(flattened_intermediate_layer_biases[i])},\")\n",
    "    else:\n",
    "        print(f\"16'b{float_to_custom_binary(flattened_intermediate_layer_biases[i])}\")\n",
    "print(\"};\")    \n",
    "\n",
    "print(\"w_enc_2_mean = {\")\n",
    "for i in range(len(flattened_z_mean_weights)):\n",
    "    if i != len(flattened_z_mean_weights)-1:\n",
    "        print(f\"16'b{float_to_custom_binary(flattened_z_mean_weights[i])},\")\n",
    "    else:\n",
    "        print(f\"16'b{float_to_custom_binary(flattened_z_mean_weights[i])}\")\n",
    "print(\"};\")\n",
    "\n",
    "print(\"b_enc_2_mean = {\")\n",
    "for i in range(len(flattened_z_mean_biases)):\n",
    "    if i != len(flattened_z_mean_biases)-1:\n",
    "        print(f\"16'b{float_to_custom_binary(flattened_z_mean_biases[i])},\")\n",
    "    else:\n",
    "        print(f\"16'b{float_to_custom_binary(flattened_z_mean_biases[i])}\")\n",
    "print(\"};\")\n",
    "\n",
    "print(\"w_enc_2_var = {\")\n",
    "for i in range(len(flattened_z_var_weights)):\n",
    "    if i != len(flattened_z_var_weights)-1:\n",
    "        print(f\"16'b{float_to_custom_binary(flattened_z_var_weights[i])},\")\n",
    "    else:\n",
    "        print(f\"16'b{float_to_custom_binary(flattened_z_var_weights[i])}\")\n",
    "print(\"};\")\n",
    "\n",
    "print(\"b_enc_2_var = {\")\n",
    "for i in range(len(flattened_z_var_biases)):\n",
    "    if i != len(flattened_z_var_biases)-1:\n",
    "        print(f\"16'b{float_to_custom_binary(flattened_z_var_biases[i])},\")\n",
    "    else:\n",
    "        print(f\"16'b{float_to_custom_binary(flattened_z_var_biases[i])}\")\n",
    "print(\"};\")\n",
    "\n",
    "print(\"w_enc_3 = {\")\n",
    "for i in range(len(flattened_hidden_classifier_weights)):\n",
    "    if i != len(flattened_hidden_classifier_weights)-1:\n",
    "        print(f\"16'b{float_to_custom_binary(flattened_hidden_classifier_weights[i])},\")\n",
    "    else:\n",
    "        print(f\"16'b{float_to_custom_binary(flattened_hidden_classifier_weights[i])}\")\n",
    "print(\"};\")\n",
    "\n",
    "print(\"b_enc_3 = {\")\n",
    "for i in range(len(flattened_hidden_classifier_biases)):\n",
    "    if i != len(flattened_hidden_classifier_biases)-1:\n",
    "        print(f\"16'b{float_to_custom_binary(flattened_hidden_classifier_biases[i])},\")\n",
    "    else:\n",
    "        print(f\"16'b{float_to_custom_binary(flattened_hidden_classifier_biases[i])}\")\n",
    "print(\"};\")\n",
    "\n",
    "print(\"w_enc_4 = {\")\n",
    "for i in range(len(flattened_classifier_output_weights)):\n",
    "    if i != len(flattened_classifier_output_weights)-1:\n",
    "        print(f\"16'b{float_to_custom_binary(flattened_classifier_output_weights[i])},\")\n",
    "    else:\n",
    "        print(f\"16'b{float_to_custom_binary(flattened_classifier_output_weights[i])}\")\n",
    "print(\"};\")\n",
    "\n",
    "print(\"b_enc_4 = {\")\n",
    "for i in range(len(flattened_classifier_output_biases)):\n",
    "    if i != len(flattened_classifier_output_biases)-1:\n",
    "        print(f\"16'b{float_to_custom_binary(flattened_classifier_output_biases[i])},\")\n",
    "    else:\n",
    "        print(f\"16'b{float_to_custom_binary(flattened_classifier_output_biases[i])}\")\n",
    "print(\"};\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w_enc_1 = {\n",
      "16'b0000010000010001,\n",
      "16'b0000010111100111,\n",
      "16'b0000010010101000,\n",
      "16'b1000000100000110,\n",
      "16'b0000001000100000,\n",
      "16'b0000001101001001,\n",
      "16'b1000000101100100,\n",
      "16'b0000001001101110,\n",
      "16'b1000101011010000,\n",
      "16'b1000001101110010,\n",
      "16'b1000001110110000,\n",
      "16'b0000100010001101,\n",
      "16'b0000001010101100,\n",
      "16'b0000010110010011,\n",
      "16'b0001000101001000,\n",
      "16'b0000001101001101,\n",
      "16'b0000001000101110,\n",
      "16'b1000110000000000,\n",
      "16'b1000001000010000,\n",
      "16'b0000001101011000,\n",
      "16'b1001001111110110,\n",
      "16'b1000100110000011,\n",
      "16'b1000010010001011,\n",
      "16'b0001001011011111,\n",
      "16'b0000001000101101,\n",
      "16'b0000010011110011,\n",
      "16'b0001000011010011,\n",
      "16'b0000001110011101,\n",
      "16'b0000010000110110,\n",
      "16'b1000101001101111,\n",
      "16'b1000001011010011,\n",
      "16'b1000001000111100,\n",
      "16'b1000101101100011,\n",
      "16'b1000000000011111,\n",
      "16'b1000000111110101,\n",
      "16'b0000010100101110,\n",
      "16'b1000000000100001,\n",
      "16'b0000011101110011,\n",
      "16'b0000110100010100,\n",
      "16'b1000001000011001,\n",
      "16'b0000000100000011,\n",
      "16'b1000011011110111,\n",
      "16'b1000001101110111,\n",
      "16'b1000001010101111,\n",
      "16'b1001001010101011,\n",
      "16'b0001001010111010,\n",
      "16'b1000001010000110,\n",
      "16'b1000000100011110,\n",
      "16'b0000001011111110,\n",
      "16'b0000011001110000,\n",
      "16'b0001010101100000,\n",
      "16'b1001000001101011,\n",
      "16'b0000001110011100,\n",
      "16'b1000000110011100,\n",
      "16'b0000000101100000,\n",
      "16'b0000010110101001,\n",
      "16'b1000100000101101,\n",
      "16'b0000101000110010,\n",
      "16'b0000000110111111,\n",
      "16'b0000010100111010,\n",
      "};\n",
      "b_enc_1 = {\n",
      "16'b0000001111101011,\n",
      "16'b0000010110111011,\n",
      "16'b1000010111111101,\n",
      "16'b1000001100001000,\n",
      "16'b0000000110100100,\n",
      "16'b1000000000111110,\n",
      "};\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Matriks weights dan biases baru\n",
    "weights = np.array([\n",
    "    [ 0.6534264,   0.21859674,  1.2745217,  -1.0222182,   0.7077743,   0.17227717],\n",
    "    [-0.20127988,  0.4514176,  -2.0522668,   2.672189,    0.80515337,  0.37432212],\n",
    "    [-0.13975152, -0.31581482,  2.3408759,  -2.3335826,  -0.33572876, -0.43321046],\n",
    "    [-0.8709897,   0.12654892, -0.26234385,  1.635064,    0.9312294,  -0.01634913],\n",
    "    [ 0.647927,   -0.24472286, -0.01513885, -1.4235544,  -0.27940372, -0.35318562],\n",
    "    [-1.3046579,   0.52666247,  0.45172158,  2.103228,    0.6189593,   0.27229634],\n",
    "    [ 2.3592968,  -0.5682007,  -1.1892892,  -2.4954329,   0.41806337, -0.25829604],\n",
    "    [-1.5002532,   0.27253047,  0.41295567,  2.1604352,   0.69707775,  0.33440912],\n",
    "    [ 1.0692248,  -0.46117586, -0.43102968, -1.3517272,   0.30404046, -0.17390116],\n",
    "    [ 0.41081432,  0.26590595, -0.12813525,  0.58229923,  0.7379277,   0.50835204]\n",
    "])\n",
    "\n",
    "biases = np.array([-0.03052479,  0.20527796, -0.3793689, -0.7488852,  0.7164985,  0.49002257])\n",
    "\n",
    "# Flattening the arrays in reverse order\n",
    "flattened_weights = weights.flatten()[::-1]\n",
    "flattened_biases = biases.flatten()[::-1]\n",
    "\n",
    "# print(\"Flattened Weights (Reversed):\", len(flattened_weights))\n",
    "# print(\"Flattened Biases (Reversed):\", flattened_biases)\n",
    "print(\"w_enc_1 = {\")\n",
    "for i in range(len(flattened_weights)):\n",
    "    print(f\"16'b{float_to_custom_binary(flattened_weights[i])},\")\n",
    "print(\"};\")    \n",
    "\n",
    "print(\"b_enc_1 = {\")\n",
    "for i in range(len(flattened_biases)):\n",
    "    print(f\"16'b{float_to_custom_binary(flattened_biases[i])},\")\n",
    "print(\"};\")    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w_enc_2_mean = {\n",
      "16'b0000011110111111,\n",
      "16'b0000001100011010,\n",
      "16'b1001000011001011,\n",
      "16'b1000101000000101,\n",
      "16'b0000011010000001,\n",
      "16'b1000110010101100\n",
      "};\n",
      "b_enc_2_mean = {\n",
      "16'b0000001000011110\n",
      "};\n",
      "w_enc_2_var = {\n",
      "16'b1001001001011000,\n",
      "16'b1001101010110101,\n",
      "16'b1001000000011100,\n",
      "16'b1001101001100110,\n",
      "16'b1001001110000011,\n",
      "16'b1001001001111010\n",
      "};\n",
      "b_enc_2_var = {\n",
      "16'b1001010110101110\n",
      "};\n",
      "w_enc_3 = {\n",
      "16'b1000010110100100,\n",
      "16'b0101010011011001,\n",
      "16'b1000100111100110,\n",
      "16'b1000100110011101,\n",
      "16'b1000100011001110,\n",
      "16'b0101101010001000\n",
      "};\n",
      "b_enc_3 = {\n",
      "16'b0000000010100000,\n",
      "16'b0000001110101100,\n",
      "16'b1000000001110110,\n",
      "16'b1000001000010001,\n",
      "16'b0000001101011000,\n",
      "16'b0000010011111101\n",
      "};\n"
     ]
    }
   ],
   "source": [
    "# Layer baru\n",
    "import numpy as np\n",
    "\n",
    "# Data untuk setiap layer\n",
    "# Data baru untuk setiap layer\n",
    "z_mean_weights = np.array([\n",
    "    [-1.584273],\n",
    "    [0.81312776],\n",
    "    [-1.252652],\n",
    "    [-2.0995972],\n",
    "    [0.38793242],\n",
    "    [0.9686]\n",
    "])\n",
    "z_mean_biases = np.array([0.26508898])\n",
    "\n",
    "z_var_weights = np.array([\n",
    "    [-2.3098145],\n",
    "    [-2.4394205],\n",
    "    [-3.3002923],\n",
    "    [-2.0141368],\n",
    "    [-3.3384168],\n",
    "    [-2.2930665]\n",
    "])\n",
    "z_var_biases = np.array([-2.7102737])\n",
    "\n",
    "hidden_classifier_weights = np.array([\n",
    "    [11.316853, -1.1008247, -1.2020463, -1.2375807, 10.606073, -0.70532894]\n",
    "])\n",
    "hidden_classifier_biases = np.array([0.6235789, 0.41815737, -0.25837928, -0.05770101, 0.45935965, 0.07813056])\n",
    "\n",
    "classifier_output_weights = np.array([\n",
    "    [2.5071313, -2.8863149],\n",
    "    [-1.1084564, 1.1964823],\n",
    "    [0.43355542, -0.08821499],\n",
    "    [-0.3390887, 0.09997902],\n",
    "    [2.4702315, -2.6811194],\n",
    "    [-0.25160715, 0.8614477]\n",
    "])\n",
    "classifier_output_biases = np.array([0.0016987, -0.00169955])\n",
    "\n",
    "# Flattening the arrays in reverse order\n",
    "flattened_z_mean_weights = z_mean_weights.flatten()[::-1]\n",
    "flattened_z_mean_biases = z_mean_biases.flatten()[::-1]\n",
    "\n",
    "flattened_z_var_weights = z_var_weights.flatten()[::-1]\n",
    "flattened_z_var_biases = z_var_biases.flatten()[::-1]\n",
    "\n",
    "flattened_hidden_classifier_weights = hidden_classifier_weights.flatten()[::-1]\n",
    "flattened_hidden_classifier_biases = hidden_classifier_biases.flatten()[::-1]\n",
    "\n",
    "flattened_classifier_output_weights = classifier_output_weights.flatten()[::-1]\n",
    "flattened_classifier_output_biases = classifier_output_biases.flatten()[::-1]\n",
    "\n",
    "print(\"w_enc_2_mean = {\")\n",
    "for i in range(len(flattened_z_mean_weights)):\n",
    "    if i != len(flattened_z_mean_weights)-1:\n",
    "        print(f\"16'b{float_to_custom_binary(flattened_z_mean_weights[i])},\")\n",
    "    else:\n",
    "        print(f\"16'b{float_to_custom_binary(flattened_z_mean_weights[i])}\")\n",
    "print(\"};\")\n",
    "\n",
    "print(\"b_enc_2_mean = {\")\n",
    "for i in range(len(flattened_z_mean_biases)):\n",
    "    if i != len(flattened_z_mean_biases)-1:\n",
    "        print(f\"16'b{float_to_custom_binary(flattened_z_mean_biases[i])},\")\n",
    "    else:\n",
    "        print(f\"16'b{float_to_custom_binary(flattened_z_mean_biases[i])}\")\n",
    "print(\"};\")\n",
    "\n",
    "print(\"w_enc_2_var = {\")\n",
    "for i in range(len(flattened_z_var_weights)):\n",
    "    if i != len(flattened_z_var_weights)-1:\n",
    "        print(f\"16'b{float_to_custom_binary(flattened_z_var_weights[i])},\")\n",
    "    else:\n",
    "        print(f\"16'b{float_to_custom_binary(flattened_z_var_weights[i])}\")\n",
    "print(\"};\")\n",
    "\n",
    "print(\"b_enc_2_var = {\")\n",
    "for i in range(len(flattened_z_var_biases)):\n",
    "    if i != len(flattened_z_var_biases)-1:\n",
    "        print(f\"16'b{float_to_custom_binary(flattened_z_var_biases[i])},\")\n",
    "    else:\n",
    "        print(f\"16'b{float_to_custom_binary(flattened_z_var_biases[i])}\")\n",
    "print(\"};\")\n",
    "\n",
    "print(\"w_enc_3 = {\")\n",
    "for i in range(len(flattened_hidden_classifier_weights)):\n",
    "    if i != len(flattened_hidden_classifier_weights)-1:\n",
    "        print(f\"16'b{float_to_custom_binary(flattened_hidden_classifier_weights[i])},\")\n",
    "    else:\n",
    "        print(f\"16'b{float_to_custom_binary(flattened_hidden_classifier_weights[i])}\")\n",
    "print(\"};\")\n",
    "\n",
    "print(\"b_enc_3 = {\")\n",
    "for i in range(len(flattened_hidden_classifier_biases)):\n",
    "    if i != len(flattened_hidden_classifier_biases)-1:\n",
    "        print(f\"16'b{float_to_custom_binary(flattened_hidden_classifier_biases[i])},\")\n",
    "    else:\n",
    "        print(f\"16'b{float_to_custom_binary(flattened_hidden_classifier_biases[i])}\")\n",
    "print(\"};\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w_enc_3 = {\n",
      "16'b1000010110100100,\n",
      "16'b0101010011011001,\n",
      "16'b1000100111100110,\n",
      "16'b1000100110011101,\n",
      "16'b1000100011001110,\n",
      "16'b0101101010001000\n",
      "};\n",
      "b_enc_3 = {\n",
      "16'b0000000010100000,\n",
      "16'b0000001110101100,\n",
      "16'b1000000001110110,\n",
      "16'b1000001000010001,\n",
      "16'b0000001101011000,\n",
      "16'b0000010011111101\n",
      "};\n"
     ]
    }
   ],
   "source": [
    "print(\"w_enc_3 = {\")\n",
    "for i in range(len(flattened_hidden_classifier_weights)):\n",
    "    if i != len(flattened_hidden_classifier_weights)-1:\n",
    "        print(f\"16'b{float_to_custom_binary(flattened_hidden_classifier_weights[i])},\")\n",
    "    else:\n",
    "        print(f\"16'b{float_to_custom_binary(flattened_hidden_classifier_weights[i])}\")\n",
    "print(\"};\")\n",
    "\n",
    "print(\"b_enc_3 = {\")\n",
    "for i in range(len(flattened_hidden_classifier_biases)):\n",
    "    if i != len(flattened_hidden_classifier_biases)-1:\n",
    "        print(f\"16'b{float_to_custom_binary(flattened_hidden_classifier_biases[i])},\")\n",
    "    else:\n",
    "        print(f\"16'b{float_to_custom_binary(flattened_hidden_classifier_biases[i])}\")\n",
    "print(\"};\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w_enc_4 = {\n",
      "16'b0000011011100100,\n",
      "16'b1000001000000011,\n",
      "16'b1001010101110010,\n",
      "16'b0001001111000011,\n",
      "16'b0000000011001100,\n",
      "16'b1000001010110110,\n",
      "16'b1000000010110100,\n",
      "16'b0000001101110111,\n",
      "16'b0000100110010010,\n",
      "16'b1000100011011110,\n",
      "16'b1001011100010111,\n",
      "16'b0001010000001110\n",
      "};\n",
      "b_enc_4 = {\n",
      "16'b1000000000000011,\n",
      "16'b0000000000000011\n",
      "};\n"
     ]
    }
   ],
   "source": [
    "print(\"w_enc_4 = {\")\n",
    "for i in range(len(flattened_classifier_output_weights)):\n",
    "    if i != len(flattened_classifier_output_weights)-1:\n",
    "        print(f\"16'b{float_to_custom_binary(flattened_classifier_output_weights[i])},\")\n",
    "    else:\n",
    "        print(f\"16'b{float_to_custom_binary(flattened_classifier_output_weights[i])}\")\n",
    "print(\"};\")\n",
    "\n",
    "print(\"b_enc_4 = {\")\n",
    "for i in range(len(flattened_classifier_output_biases)):\n",
    "    if i != len(flattened_classifier_output_biases)-1:\n",
    "        print(f\"16'b{float_to_custom_binary(flattened_classifier_output_biases[i])},\")\n",
    "    else:\n",
    "        print(f\"16'b{float_to_custom_binary(flattened_classifier_output_biases[i])}\")\n",
    "print(\"};\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
